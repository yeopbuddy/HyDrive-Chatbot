import json
import re
from typing import List, Dict, Any
from pathlib import Path

class SimpleSearchService:
    def __init__(self, data_path: str = "./data/processed/"):
        self.data_path = Path(data_path)
        self.documents = []
        self.sections_data = []
        
    def add_document(self, json_data: Dict[str, Any]):
        """ìƒˆ JSON ë¬¸ì„œ ì¶”ê°€"""
        if "sections" not in json_data:
            print("âŒ sections í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        self.documents = [json_data]
        vehicle_name = self._extract_vehicle_name_from_data(json_data)
        sections_count = len(json_data.get("sections", []))
        
        print(f"ðŸ“„ {vehicle_name} ë§¤ë‰´ì–¼ ì¶”ê°€: {sections_count}ê°œ ì„¹ì…˜")
        
        # ì„¹ì…˜ ë°ì´í„° ì¤€ë¹„
        self._prepare_sections_data(json_data)
    
    def _prepare_sections_data(self, json_data: Dict[str, Any]):
        """ì„¹ì…˜ ë°ì´í„°ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¤€ë¹„"""
        self.sections_data = []
        
        for section in json_data.get("sections", []):
            section_data = {
                "source": json_data.get("file_name", "unknown"),
                "section_number": section.get("section_number", ""),
                "title": section.get("title", ""),
                "page_range": section.get("page_range", ""),
                "content": section.get("content", ""),
                "keywords": section.get("keywords", []),
                "subsections": section.get("subsections", [])
            }
            self.sections_data.append(section_data)
        
        print(f"âœ… {len(self.sections_data)}ê°œ ì„¹ì…˜ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    
    def search_sections(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì„¹ì…˜ ê²€ìƒ‰"""
        
        if not self.documents or not self.sections_data:
            print("âš ï¸ ë¡œë“œëœ ë¬¸ì„œë‚˜ ì„¹ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        vehicle_name = self._extract_vehicle_name_from_data(self.documents[0])
        print(f"ðŸ” {vehicle_name} ë§¤ë‰´ì–¼ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œìž‘: '{query}'")
        
        search_results = []
        
        # ê° ì„¹ì…˜ì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°
        for section_data in self.sections_data:
            scores = self._calculate_all_scores(query, section_data)
            total_score = self._calculate_total_score(scores)
            
            if total_score > 0.05:  # ìž„ê³„ê°’
                search_results.append({
                    "score": total_score,
                    "source": section_data["source"],
                    "section_number": section_data["section_number"],
                    "title": section_data["title"],
                    "page_range": section_data["page_range"],
                    "content": section_data["content"],
                    "keywords": section_data["keywords"],
                    "subsections": section_data["subsections"],
                    "match_details": {
                        "title_score": round(scores["title"], 3),
                        "keyword_score": round(scores["keyword"], 3),
                        "content_score": round(scores["content"], 3),
                        "bonus_score": round(scores["bonus"], 3)
                    }
                })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        search_results.sort(key=lambda x: x["score"], reverse=True)
        
        print(f"ðŸ“Š {vehicle_name} ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ì„¹ì…˜ (í‚¤ì›Œë“œ ë§¤ì¹­)")
        for i, result in enumerate(search_results[:3]):
            print(f"  {i+1}. [{result['score']:.3f}] {result['title']} (íŽ˜ì´ì§€ {result['page_range']})")
        
        return search_results[:k]
    
    def _calculate_all_scores(self, query: str, section_data: Dict) -> Dict[str, float]:
        """ëª¨ë“  ì ìˆ˜ ê³„ì‚°"""
        return {
            "title": self._calculate_title_score(query, section_data["title"]),
            "keyword": self._calculate_keyword_score(query, section_data["keywords"]),
            "content": self._calculate_content_score(query, section_data["content"]),
            "bonus": self._calculate_bonus_score(query, section_data)
        }
    
    def _calculate_total_score(self, scores: Dict[str, float]) -> float:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        return (scores["title"] * 0.4) + (scores["keyword"] * 0.3) + \
               (scores["content"] * 0.2) + (scores["bonus"] * 0.1)
    
    def _calculate_title_score(self, query: str, title: str) -> float:
        """ì œëª© ë§¤ì¹­ ì ìˆ˜"""
        if not title:
            return 0
        
        query_words = set(self._tokenize(query))
        title_words = set(self._tokenize(title))
        
        # ì™„ì „ ë§¤ì¹­
        exact_matches = len(query_words.intersection(title_words))
        
        # ë¶€ë¶„ ë§¤ì¹­
        partial_matches = 0
        for q_word in query_words:
            for t_word in title_words:
                if q_word in t_word or t_word in q_word:
                    partial_matches += 0.5
                    break
        
        total_matches = exact_matches + partial_matches
        return min(total_matches / max(len(query_words), 1), 1.0)
    
    def _calculate_keyword_score(self, query: str, keywords: List[str]) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜"""
        if not keywords:
            return 0
        
        query_lower = query.lower()
        matches = 0
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in query_lower:
                matches += 1
            elif any(word in keyword_lower for word in self._tokenize(query)):
                matches += 0.5
        
        return min(matches / max(len(keywords), 1), 1.0)
    
    def _calculate_content_score(self, query: str, content: str) -> float:
        """ì½˜í…ì¸  ë§¤ì¹­ ì ìˆ˜"""
        if not content:
            return 0
        
        content_lower = content.lower()
        query_words = self._tokenize(query)
        
        # ë‹¨ì–´ë³„ ë§¤ì¹­ íšŸìˆ˜ ê³„ì‚°
        total_matches = 0
        for word in query_words:
            # ì™„ì „ ë§¤ì¹­
            exact_count = content_lower.count(word.lower())
            total_matches += exact_count
            
            # ë¶€ë¶„ ë§¤ì¹­ (ê¸¸ì´ 3 ì´ìƒì¸ ë‹¨ì–´ë§Œ)
            if len(word) >= 3:
                partial_count = len(re.findall(rf'{re.escape(word.lower())}', content_lower))
                total_matches += partial_count * 0.5
        
        # ì½˜í…ì¸  ê¸¸ì´ë¡œ ì •ê·œí™”
        content_length = len(content)
        if content_length > 0:
            return min(total_matches / (content_length / 100), 1.0)
        
        return 0
    
    def _calculate_bonus_score(self, query: str, section: Dict) -> float:
        """ë³´ë„ˆìŠ¤ ì ìˆ˜"""
        content = section.get("content", "").lower()
        title = section.get("title", "").lower()
        query_lower = query.lower()
        bonus = 0
        
        # ë°©ë²•, ì ˆì°¨ ê´€ë ¨ ë³´ë„ˆìŠ¤
        if any(word in query_lower for word in ["ë°©ë²•", "ì ˆì°¨", "ì–´ë–»ê²Œ", "how"]):
            if any(word in content for word in ["ë°©ë²•", "ì ˆì°¨", "ë‹¨ê³„", "í•˜ì‹­ì‹œì˜¤", "ìˆœì„œ"]):
                bonus += 0.3
        
        # ë¬¸ì œ í•´ê²° ê´€ë ¨ ë³´ë„ˆìŠ¤
        if any(word in query_lower for word in ["ë¬¸ì œ", "ì˜¤ë¥˜", "ê³ ìž¥", "ì•ˆë¨", "ìž‘ë™"]):
            if any(word in content for word in ["ì ê²€", "í™•ì¸", "êµì²´", "ì •ë¹„", "ìˆ˜ë¦¬"]):
                bonus += 0.2
        
        # ì œëª©ì— ì¤‘ìš” í‚¤ì›Œë“œê°€ ìžˆëŠ” ê²½ìš°
        if any(word in title for word in ["ì•ˆì „", "ì£¼ì˜", "ê²½ê³ ", "ì¤‘ìš”"]):
            bonus += 0.1
        
        return min(bonus, 1.0)
    
    def _tokenize(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„ë¦¬"""
        if not text:
            return []
        
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìžë§Œ ì¶”ì¶œ
        tokens = re.findall(r'[ê°€-íž£a-zA-Z0-9]+', text.lower())
        
        # ê¸¸ì´ 1ì¸ í† í° ì œê±° (ë‹¨, ìˆ«ìžëŠ” ìœ ì§€)
        tokens = [token for token in tokens if len(token) > 1 or token.isdigit()]
        
        return tokens
    
    def _extract_vehicle_name_from_data(self, json_data: Dict[str, Any]) -> str:
        """JSON ë°ì´í„°ì—ì„œ ì°¨ëŸ‰ëª… ì¶”ì¶œ"""
        file_name = json_data.get("file_name", "").lower()
        
        if "ê·¸ëžœì €" in file_name or "granjer" in file_name or "grandeur" in file_name:
            return "ê·¸ëžœì €"
        elif "ì‹¼íƒ€íŽ˜" in file_name or "santafe" in file_name:
            return "ì‹¼íƒ€íŽ˜"
        elif "ì˜ë‚˜íƒ€" in file_name or "sonata" in file_name:
            return "ì˜ë‚˜íƒ€"
        elif "ì•„ë°˜ë–¼" in file_name or "avante" in file_name:
            return "ì•„ë°˜ë–¼"
        elif "ì½”ë‚˜" in file_name or "kona" in file_name:
            return "ì½”ë‚˜"
        elif "íˆ¬ì‹¼" in file_name or "tucson" in file_name:
            return "íˆ¬ì‹¼"
        elif "íŽ ë¦¬ì„¸ì´ë“œ" in file_name or "íŒ°ë¦¬ì„¸ì´ë“œ" in file_name or "palisade" in file_name:
            return "íŽ ë¦¬ì„¸ì´ë“œ"
        
        return "unknown"
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        return {
            "documents_count": len(self.documents),
            "total_sections": len(self.sections_data),
            "search_method": "keyword_matching"
        }